Normally the first step in debugging is to attempt to reproduce the problem.
For example, when a bug in a compiler can make it crash when parsing some large source file, a simplification of the test case that results in only few lines from the original source file can be sufficient to reproduce the same crash.
 Different programming languages support different styles of programming (called programming paradigms).
Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" â€“ a series of pasteboard cards with holes punched in them.
