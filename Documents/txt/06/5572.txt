 Whatever the approach to development may be, the final program must satisfy some fundamental properties.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.

Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
 It is very difficult to determine what are the most popular modern programming languages.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
For example, when a bug in a compiler can make it crash when parsing some large source file, a simplification of the test case that results in only few lines from the original source file can be sufficient to reproduce the same crash.
Many applications use a mix of several languages in their construction and use.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
 Programmable devices have existed for centuries.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
Languages form an approximate spectrum from "low-level" to "high-level"; "low-level" languages are typically more machine-oriented and faster to execute, whereas "high-level" languages are more abstract and easier to use but execute less quickly.
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.