 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
It is usually easier to code in "high-level" languages than in "low-level" ones.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
 Programs were mostly entered using punched cards or paper tape.

 These compiled languages allow the programmer to write programs in terms that are syntactically richer, and more capable of abstracting the code, making it easy to target varying machine instruction sets via compilation declarations and heuristics.
For example, when a bug in a compiler can make it crash when parsing some large source file, a simplification of the test case that results in only few lines from the original source file can be sufficient to reproduce the same crash.
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Ideally, the programming language best suited for the task at hand will be selected.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.