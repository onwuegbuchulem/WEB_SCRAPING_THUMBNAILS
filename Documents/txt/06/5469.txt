Many programmers use forms of Agile software development where the various stages of formal software development are more integrated together into short cycles that take a few weeks rather than years.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" â€“ a series of pasteboard cards with holes punched in them.
Sometimes software development is known as software engineering, especially when it employs formal methods or follows an engineering design process.
It is usually easier to code in "high-level" languages than in "low-level" ones.
 These compiled languages allow the programmer to write programs in terms that are syntactically richer, and more capable of abstracting the code, making it easy to target varying machine instruction sets via compilation declarations and heuristics.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
Normally the first step in debugging is to attempt to reproduce the problem.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
 The first step in most formal software development processes is requirements analysis, followed by testing to determine value modeling, implementation, and failure elimination (debugging).