In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
 Programs were mostly entered using punched cards or paper tape.
 These compiled languages allow the programmer to write programs in terms that are syntactically richer, and more capable of abstracting the code, making it easy to target varying machine instruction sets via compilation declarations and heuristics.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
Sometimes software development is known as software engineering, especially when it employs formal methods or follows an engineering design process.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.
 Readability is important because programmers spend the majority of their time reading, trying to understand, reusing and modifying existing source code, rather than writing new source code.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
However, because an assembly language is little more than a different notation for a machine language,  two machines with different instruction sets also have different assembly languages.
It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.