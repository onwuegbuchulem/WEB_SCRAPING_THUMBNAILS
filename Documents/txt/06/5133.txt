There exist a lot of different approaches for each of those tasks.
 Different programming languages support different styles of programming (called programming paradigms).
It affects the aspects of quality above, including portability, usability and most importantly maintainability.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.
One approach popular for requirements analysis is Use Case analysis.
 These compiled languages allow the programmer to write programs in terms that are syntactically richer, and more capable of abstracting the code, making it easy to target varying machine instruction sets via compilation declarations and heuristics.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
 Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display.
For example, when a bug in a compiler can make it crash when parsing some large source file, a simplification of the test case that results in only few lines from the original source file can be sufficient to reproduce the same crash.
 Programs were mostly entered using punched cards or paper tape.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.