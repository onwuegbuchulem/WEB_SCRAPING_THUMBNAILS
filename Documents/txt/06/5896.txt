The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
While these are sometimes considered programming, often the term software development is used for this larger overall process â€“ with the terms programming, implementation, and coding reserved for the writing and editing of code per se.
However, because an assembly language is little more than a different notation for a machine language,  two machines with different instruction sets also have different assembly languages.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
Proficient programming usually requires expertise in several different subjects, including knowledge of the application domain, details of programming languages and generic code libraries, specialized algorithms, and formal logic.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
Many applications use a mix of several languages in their construction and use.
Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute.
However, readability is more than just programming style.
In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where a musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams.
It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
Their jobs usually involve:
 Although programming has been presented in the media as a somewhat mathematical subject, some research shows that good programmers have strong skills in natural human languages, and that learning to code is similar to learning a foreign language.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.