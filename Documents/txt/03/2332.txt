 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
 Programs were mostly entered using punched cards or paper tape.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
This can be a non-trivial task, for example as with parallel processes or some unusual software bugs.
Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute.
Later a control panel (plug board) added to his 1906 Type I Tabulator allowed it to be programmed for different jobs, and by the late 1940s, unit record equipment such as the IBM 602 and IBM 604, were programmed by control panels in a similar way, as were the first electronic computers.
 Code-breaking algorithms have also existed for centuries.
Integrated development environments (IDEs) aim to integrate all such help.
 Following a consistent programming style often helps readability.
 Programmable devices have existed for centuries.
Normally the first step in debugging is to attempt to reproduce the problem.
 It is very difficult to determine what are the most popular modern programming languages.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
Proficient programming usually requires expertise in several different subjects, including knowledge of the application domain, details of programming languages and generic code libraries, specialized algorithms, and formal logic.