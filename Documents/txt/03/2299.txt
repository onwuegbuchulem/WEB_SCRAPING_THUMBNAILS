Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
 Programs were mostly entered using punched cards or paper tape.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Techniques like Code refactoring can enhance readability.
There are many approaches to the Software development process.
 Whatever the approach to development may be, the final program must satisfy some fundamental properties.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.