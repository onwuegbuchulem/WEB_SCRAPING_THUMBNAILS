There exist a lot of different approaches for each of those tasks.
Normally the first step in debugging is to attempt to reproduce the problem.
It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" â€“ a series of pasteboard cards with holes punched in them.
 Programs were mostly entered using punched cards or paper tape.
Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
 Following a consistent programming style often helps readability.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
It is usually easier to code in "high-level" languages than in "low-level" ones.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
Later a control panel (plug board) added to his 1906 Type I Tabulator allowed it to be programmed for different jobs, and by the late 1940s, unit record equipment such as the IBM 602 and IBM 604, were programmed by control panels in a similar way, as were the first electronic computers.