 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
There are many approaches to the Software development process.
FORTRAN, the first widely used high-level language to have a functional implementation, came out in 1957, and many other languages were soon developedâ€”in particular, COBOL aimed at commercial data processing, and Lisp for computer research.
Many applications use a mix of several languages in their construction and use.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.
In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where a musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
Techniques like Code refactoring can enhance readability.
 Programs were mostly entered using punched cards or paper tape.
This can be a non-trivial task, for example as with parallel processes or some unusual software bugs.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.