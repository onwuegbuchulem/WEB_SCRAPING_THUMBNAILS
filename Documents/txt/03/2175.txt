 Programs were mostly entered using punched cards or paper tape.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
There are many approaches to the Software development process.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.

 Computer programming or coding is the composition of sequences of instructions, called programs, that computers can follow to perform tasks.
This can be a non-trivial task, for example as with parallel processes or some unusual software bugs.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.