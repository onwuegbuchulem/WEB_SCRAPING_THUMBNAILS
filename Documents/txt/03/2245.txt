For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
 Programs were mostly entered using punched cards or paper tape.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
Trial-and-error/divide-and-conquer is needed: the programmer will try to remove some parts of the original test case and check if the problem still exists.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
Proficient programming usually requires expertise in several different subjects, including knowledge of the application domain, details of programming languages and generic code libraries, specialized algorithms, and formal logic.
It is usually easier to code in "high-level" languages than in "low-level" ones.
As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices.

Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
One approach popular for requirements analysis is Use Case analysis.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
However, with the concept of the stored-program computer introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.