 Programmable devices have existed for centuries.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
Some of these factors include:
 The presentation aspects of this (such as indents, line breaks, color highlighting, and so on) are often handled by the source code editor, but the content aspects reflect the programmer's talent and skills.
However, readability is more than just programming style.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
 It is very difficult to determine what are the most popular modern programming languages.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
 These compiled languages allow the programmer to write programs in terms that are syntactically richer, and more capable of abstracting the code, making it easy to target varying machine instruction sets via compilation declarations and heuristics.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.
While these are sometimes considered programming, often the term software development is used for this larger overall process â€“ with the terms programming, implementation, and coding reserved for the writing and editing of code per se.

There are many approaches to the Software development process.
Techniques like Code refactoring can enhance readability.
In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where a musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams.