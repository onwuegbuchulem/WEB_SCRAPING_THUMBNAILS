The following properties are among the most important:

 In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
 New languages are generally designed around the syntax of a prior language with new functionality added, (for example C++ adds object-orientation to C, and Java adds memory management and bytecode to C++, but as a result, loses efficiency and the ability for low-level manipulation).
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
Proficient programming usually requires expertise in several different subjects, including knowledge of the application domain, details of programming languages and generic code libraries, specialized algorithms, and formal logic.
Normally the first step in debugging is to attempt to reproduce the problem.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
 It is very difficult to determine what are the most popular modern programming languages.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.