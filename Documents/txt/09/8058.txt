 Readability is important because programmers spend the majority of their time reading, trying to understand, reusing and modifying existing source code, rather than writing new source code.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
It is usually easier to code in "high-level" languages than in "low-level" ones.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.
However, with the concept of the stored-program computer introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.

Some of these factors include:
 The presentation aspects of this (such as indents, line breaks, color highlighting, and so on) are often handled by the source code editor, but the content aspects reflect the programmer's talent and skills.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
However, readability is more than just programming style.