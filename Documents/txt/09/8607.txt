A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
 It is very difficult to determine what are the most popular modern programming languages.
 Programs were mostly entered using punched cards or paper tape.
 Programmable devices have existed for centuries.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
Many applications use a mix of several languages in their construction and use.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
Scripting and breakpointing is also part of this process.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.
Integrated development environments (IDEs) aim to integrate all such help.
It is usually easier to code in "high-level" languages than in "low-level" ones.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.