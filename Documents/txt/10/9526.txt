A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
 These compiled languages allow the programmer to write programs in terms that are syntactically richer, and more capable of abstracting the code, making it easy to target varying machine instruction sets via compilation declarations and heuristics.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
 Following a consistent programming style often helps readability.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
Use of a static code analysis tool can help detect some possible problems.
Proficient programming usually requires expertise in several different subjects, including knowledge of the application domain, details of programming languages and generic code libraries, specialized algorithms, and formal logic.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
 Different programming languages support different styles of programming (called programming paradigms).
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
One approach popular for requirements analysis is Use Case analysis.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.