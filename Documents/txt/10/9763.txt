 New languages are generally designed around the syntax of a prior language with new functionality added, (for example C++ adds object-orientation to C, and Java adds memory management and bytecode to C++, but as a result, loses efficiency and the ability for low-level manipulation).
Trial-and-error/divide-and-conquer is needed: the programmer will try to remove some parts of the original test case and check if the problem still exists.
Programming languages are essential for software development.
Scripting and breakpointing is also part of this process.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
Ideally, the programming language best suited for the task at hand will be selected.

Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
 Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
 Different programming languages support different styles of programming (called programming paradigms).
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" â€“ a series of pasteboard cards with holes punched in them.