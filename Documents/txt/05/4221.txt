Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" – a series of pasteboard cards with holes punched in them.
Many programmers use forms of Agile software development where the various stages of formal software development are more integrated together into short cycles that take a few weeks rather than years.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
However, with the concept of the stored-program computer introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.

 Computer programming or coding is the composition of sequences of instructions, called programs, that computers can follow to perform tasks.
FORTRAN, the first widely used high-level language to have a functional implementation, came out in 1957, and many other languages were soon developed—in particular, COBOL aimed at commercial data processing, and Lisp for computer research.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
 Programs were mostly entered using punched cards or paper tape.
One approach popular for requirements analysis is Use Case analysis.