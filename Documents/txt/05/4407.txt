
The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where a musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams.
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
 Programs were mostly entered using punched cards or paper tape.
This can be a non-trivial task, for example as with parallel processes or some unusual software bugs.
It affects the aspects of quality above, including portability, usability and most importantly maintainability.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
There are many approaches to the Software development process.
Programming languages are essential for software development.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
Techniques like Code refactoring can enhance readability.