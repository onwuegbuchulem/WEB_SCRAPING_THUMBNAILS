 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.
There are many approaches to the Software development process.
 Programmable devices have existed for centuries.
 Different programming languages support different styles of programming (called programming paradigms).
Ideally, the programming language best suited for the task at hand will be selected.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
Their jobs usually involve:
 Although programming has been presented in the media as a somewhat mathematical subject, some research shows that good programmers have strong skills in natural human languages, and that learning to code is similar to learning a foreign language.
While these are sometimes considered programming, often the term software development is used for this larger overall process â€“ with the terms programming, implementation, and coding reserved for the writing and editing of code per se.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
 Programs were mostly entered using punched cards or paper tape.
 The first step in most formal software development processes is requirements analysis, followed by testing to determine value modeling, implementation, and failure elimination (debugging).