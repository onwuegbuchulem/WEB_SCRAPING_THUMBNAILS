It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
Scripting and breakpointing is also part of this process.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
It affects the aspects of quality above, including portability, usability and most importantly maintainability.
 The first step in most formal software development processes is requirements analysis, followed by testing to determine value modeling, implementation, and failure elimination (debugging).
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
Languages form an approximate spectrum from "low-level" to "high-level"; "low-level" languages are typically more machine-oriented and faster to execute, whereas "high-level" languages are more abstract and easier to use but execute less quickly.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.
It is usually easier to code in "high-level" languages than in "low-level" ones.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" â€“ a series of pasteboard cards with holes punched in them.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.