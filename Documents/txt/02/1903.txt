Normally the first step in debugging is to attempt to reproduce the problem.
The following properties are among the most important:

 In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code.
Trial-and-error/divide-and-conquer is needed: the programmer will try to remove some parts of the original test case and check if the problem still exists.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
Proficient programming usually requires expertise in several different subjects, including knowledge of the application domain, details of programming languages and generic code libraries, specialized algorithms, and formal logic.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.