Programming languages are essential for software development.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
Use of a static code analysis tool can help detect some possible problems.
Many applications use a mix of several languages in their construction and use.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
Later a control panel (plug board) added to his 1906 Type I Tabulator allowed it to be programmed for different jobs, and by the late 1940s, unit record equipment such as the IBM 602 and IBM 604, were programmed by control panels in a similar way, as were the first electronic computers.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
It is usually easier to code in "high-level" languages than in "low-level" ones.
 Programs were mostly entered using punched cards or paper tape.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).