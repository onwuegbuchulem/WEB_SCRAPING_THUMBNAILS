FORTRAN, the first widely used high-level language to have a functional implementation, came out in 1957, and many other languages were soon developedâ€”in particular, COBOL aimed at commercial data processing, and Lisp for computer research.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
Methods of measuring programming language popularity include: counting the number of job advertisements that mention the language, the number of books sold and courses teaching the language (this overestimates the importance of newer languages), and estimates of the number of existing lines of code written in the language (this underestimates the number of users of business languages such as COBOL).
 Whatever the approach to development may be, the final program must satisfy some fundamental properties.
For example, when a bug in a compiler can make it crash when parsing some large source file, a simplification of the test case that results in only few lines from the original source file can be sufficient to reproduce the same crash.
Some of these factors include:
 The presentation aspects of this (such as indents, line breaks, color highlighting, and so on) are often handled by the source code editor, but the content aspects reflect the programmer's talent and skills.
Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
However, because an assembly language is little more than a different notation for a machine language,  two machines with different instruction sets also have different assembly languages.
 Following a consistent programming style often helps readability.
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
Many programmers use forms of Agile software development where the various stages of formal software development are more integrated together into short cycles that take a few weeks rather than years.