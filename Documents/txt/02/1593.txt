 The first step in most formal software development processes is requirements analysis, followed by testing to determine value modeling, implementation, and failure elimination (debugging).
FORTRAN, the first widely used high-level language to have a functional implementation, came out in 1957, and many other languages were soon developedâ€”in particular, COBOL aimed at commercial data processing, and Lisp for computer research.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
 Different programming languages support different styles of programming (called programming paradigms).
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
One approach popular for requirements analysis is Use Case analysis.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
Later a control panel (plug board) added to his 1906 Type I Tabulator allowed it to be programmed for different jobs, and by the late 1940s, unit record equipment such as the IBM 602 and IBM 604, were programmed by control panels in a similar way, as were the first electronic computers.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.

 Computer programming or coding is the composition of sequences of instructions, called programs, that computers can follow to perform tasks.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.