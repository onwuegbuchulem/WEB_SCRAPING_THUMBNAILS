 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
Ideally, the programming language best suited for the task at hand will be selected.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" â€“ a series of pasteboard cards with holes punched in them.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
 Programs were mostly entered using punched cards or paper tape.
Normally the first step in debugging is to attempt to reproduce the problem.
 It is very difficult to determine what are the most popular modern programming languages.