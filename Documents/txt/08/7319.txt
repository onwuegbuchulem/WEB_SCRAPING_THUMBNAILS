By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.

 Computer programming or coding is the composition of sequences of instructions, called programs, that computers can follow to perform tasks.
 Whatever the approach to development may be, the final program must satisfy some fundamental properties.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
However, with the concept of the stored-program computer introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.
It affects the aspects of quality above, including portability, usability and most importantly maintainability.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
This can be a non-trivial task, for example as with parallel processes or some unusual software bugs.
Their jobs usually involve:
 Although programming has been presented in the media as a somewhat mathematical subject, some research shows that good programmers have strong skills in natural human languages, and that learning to code is similar to learning a foreign language.
In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where a musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams.
Sometimes software development is known as software engineering, especially when it employs formal methods or follows an engineering design process.
Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
 Auxiliary tasks accompanying and related to programming include analyzing requirements, testing, debugging (investigating and fixing problems), implementation of build systems, and management of derived artifacts, such as programs' machine code.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.