 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
 Different programming languages support different styles of programming (called programming paradigms).
 Following a consistent programming style often helps readability.
Scripting and breakpointing is also part of this process.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
It affects the aspects of quality above, including portability, usability and most importantly maintainability.
There exist a lot of different approaches for each of those tasks.