Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
 Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
 These compiled languages allow the programmer to write programs in terms that are syntactically richer, and more capable of abstracting the code, making it easy to target varying machine instruction sets via compilation declarations and heuristics.
Scripting and breakpointing is also part of this process.
 Programmable devices have existed for centuries.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
 Different programming languages support different styles of programming (called programming paradigms).