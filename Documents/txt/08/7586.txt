Normally the first step in debugging is to attempt to reproduce the problem.
 Readability is important because programmers spend the majority of their time reading, trying to understand, reusing and modifying existing source code, rather than writing new source code.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
Some of these factors include:
 The presentation aspects of this (such as indents, line breaks, color highlighting, and so on) are often handled by the source code editor, but the content aspects reflect the programmer's talent and skills.
There exist a lot of different approaches for each of those tasks.
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
 Code-breaking algorithms have also existed for centuries.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
It affects the aspects of quality above, including portability, usability and most importantly maintainability.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
FORTRAN, the first widely used high-level language to have a functional implementation, came out in 1957, and many other languages were soon developedâ€”in particular, COBOL aimed at commercial data processing, and Lisp for computer research.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
Trial-and-error/divide-and-conquer is needed: the programmer will try to remove some parts of the original test case and check if the problem still exists.