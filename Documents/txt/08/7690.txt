
 Computer programming or coding is the composition of sequences of instructions, called programs, that computers can follow to perform tasks.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.

 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
Normally the first step in debugging is to attempt to reproduce the problem.
One approach popular for requirements analysis is Use Case analysis.
 Programs were mostly entered using punched cards or paper tape.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute.
Languages form an approximate spectrum from "low-level" to "high-level"; "low-level" languages are typically more machine-oriented and faster to execute, whereas "high-level" languages are more abstract and easier to use but execute less quickly.
Sometimes software development is known as software engineering, especially when it employs formal methods or follows an engineering design process.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
 New languages are generally designed around the syntax of a prior language with new functionality added, (for example C++ adds object-orientation to C, and Java adds memory management and bytecode to C++, but as a result, loses efficiency and the ability for low-level manipulation).