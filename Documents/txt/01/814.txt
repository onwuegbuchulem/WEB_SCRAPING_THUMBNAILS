 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
For example, when a bug in a compiler can make it crash when parsing some large source file, a simplification of the test case that results in only few lines from the original source file can be sufficient to reproduce the same crash.
Methods of measuring programming language popularity include: counting the number of job advertisements that mention the language, the number of books sold and courses teaching the language (this overestimates the importance of newer languages), and estimates of the number of existing lines of code written in the language (this underestimates the number of users of business languages such as COBOL).
 Readability is important because programmers spend the majority of their time reading, trying to understand, reusing and modifying existing source code, rather than writing new source code.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.
Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute.
Integrated development environments (IDEs) aim to integrate all such help.
 Programs were mostly entered using punched cards or paper tape.
 It is very difficult to determine what are the most popular modern programming languages.
 Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users.
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.