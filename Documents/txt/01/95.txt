Also, specific user environment and usage history can make it difficult to reproduce the problem.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
 Following a consistent programming style often helps readability.
 Programmable devices have existed for centuries.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
One approach popular for requirements analysis is Use Case analysis.
 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
 Debugging is often done with IDEs. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line.
There are many approaches to the Software development process.