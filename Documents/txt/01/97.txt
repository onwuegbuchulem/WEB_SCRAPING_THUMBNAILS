 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
Scripting and breakpointing is also part of this process.
While these are sometimes considered programming, often the term software development is used for this larger overall process â€“ with the terms programming, implementation, and coding reserved for the writing and editing of code per se.
Normally the first step in debugging is to attempt to reproduce the problem.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.
It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.
 Following a consistent programming style often helps readability.
Ideally, the programming language best suited for the task at hand will be selected.
There exist a lot of different approaches for each of those tasks.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
 Programmable devices have existed for centuries.
 High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware.