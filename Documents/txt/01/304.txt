Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
Trial-and-error/divide-and-conquer is needed: the programmer will try to remove some parts of the original test case and check if the problem still exists.
Many programmers use forms of Agile software development where the various stages of formal software development are more integrated together into short cycles that take a few weeks rather than years.
Techniques like Code refactoring can enhance readability.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
Ideally, the programming language best suited for the task at hand will be selected.
One approach popular for requirements analysis is Use Case analysis.
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.
 Programs were mostly entered using punched cards or paper tape.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.