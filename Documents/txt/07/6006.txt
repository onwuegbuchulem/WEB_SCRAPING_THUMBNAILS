 Different programming languages support different styles of programming (called programming paradigms).
 In the 1880s, Herman Hollerith invented the concept of storing data in machine-readable form.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
 Code-breaking algorithms have also existed for centuries.
However, Charles Babbage had already written his first program for the Analytical Engine in 1837.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.
 Programmable devices have existed for centuries.
While these are sometimes considered programming, often the term software development is used for this larger overall process â€“ with the terms programming, implementation, and coding reserved for the writing and editing of code per se.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
Their jobs usually involve:
 Although programming has been presented in the media as a somewhat mathematical subject, some research shows that good programmers have strong skills in natural human languages, and that learning to code is similar to learning a foreign language.
One approach popular for requirements analysis is Use Case analysis.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
 Auxiliary tasks accompanying and related to programming include analyzing requirements, testing, debugging (investigating and fixing problems), implementation of build systems, and management of derived artifacts, such as programs' machine code.