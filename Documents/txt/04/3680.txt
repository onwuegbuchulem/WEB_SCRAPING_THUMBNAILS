It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
Normally the first step in debugging is to attempt to reproduce the problem.
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.

The first compiler related tool, the A-0 System, was developed in 1952 by Grace Hopper, who also coined the term 'compiler'.
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.
Languages form an approximate spectrum from "low-level" to "high-level"; "low-level" languages are typically more machine-oriented and faster to execute, whereas "high-level" languages are more abstract and easier to use but execute less quickly.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
 Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display.
Their jobs usually involve:
 Although programming has been presented in the media as a somewhat mathematical subject, some research shows that good programmers have strong skills in natural human languages, and that learning to code is similar to learning a foreign language.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
Some of these factors include:
 The presentation aspects of this (such as indents, line breaks, color highlighting, and so on) are often handled by the source code editor, but the content aspects reflect the programmer's talent and skills.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).