 Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
Many applications use a mix of several languages in their construction and use.
 Programmable devices have existed for centuries.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices.
While these are sometimes considered programming, often the term software development is used for this larger overall process – with the terms programming, implementation, and coding reserved for the writing and editing of code per se.
It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.
 Whatever the approach to development may be, the final program must satisfy some fundamental properties.
In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" – a series of pasteboard cards with holes punched in them.
He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.
The following properties are among the most important:

 In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
 Different programming languages support different styles of programming (called programming paradigms).