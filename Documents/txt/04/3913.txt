 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
This can be a non-trivial task, for example as with parallel processes or some unusual software bugs.
For example, when a bug in a compiler can make it crash when parsing some large source file, a simplification of the test case that results in only few lines from the original source file can be sufficient to reproduce the same crash.
 Readability is important because programmers spend the majority of their time reading, trying to understand, reusing and modifying existing source code, rather than writing new source code.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
 Following a consistent programming style often helps readability.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
Later a control panel (plug board) added to his 1906 Type I Tabulator allowed it to be programmed for different jobs, and by the late 1940s, unit record equipment such as the IBM 602 and IBM 604, were programmed by control panels in a similar way, as were the first electronic computers.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
Sometimes software development is known as software engineering, especially when it employs formal methods or follows an engineering design process.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.