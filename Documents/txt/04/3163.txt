 The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
Use of a static code analysis tool can help detect some possible problems.
There exist a lot of different approaches for each of those tasks.
Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly executed by the central processing unit.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
 Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display.
Ideally, the programming language best suited for the task at hand will be selected.
Programming languages are essential for software development.
 Different programming languages support different styles of programming (called programming paradigms).
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
 A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference.