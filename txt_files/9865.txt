However, with the concept of the stored-program computer introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
Normally the first step in debugging is to attempt to reproduce the problem.
The purpose of programming is to find a sequence of instructions that will automate the performance of a task (which can be as complex as an operating system) on a computer, often for solving a given problem.
Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
It is usually easier to code in "high-level" languages than in "low-level" ones.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
Ideally, the programming language best suited for the task at hand will be selected.
Scripting and breakpointing is also part of this process.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.
 The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
Transpiling on the other hand, takes the source-code from a high-level programming language and converts it into bytecode.
Trial-and-error/divide-and-conquer is needed: the programmer will try to remove some parts of the original test case and check if the problem still exists.
Techniques like Code refactoring can enhance readability.