Also, specific user environment and usage history can make it difficult to reproduce the problem.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.
It affects the aspects of quality above, including portability, usability and most importantly maintainability.
Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute.
Techniques like Code refactoring can enhance readability.
Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
It is usually easier to code in "high-level" languages than in "low-level" ones.
However, with the concept of the stored-program computer introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.
 After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug.
Compilers harnessed the power of computers to make programming easier by allowing programmers to specify calculations by entering a formula using infix notation.
There exist a lot of different approaches for each of those tasks.
 Following a consistent programming style often helps readability.