By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
Compiling takes the source code from a low-level programming language and converts it into machine code.
However, with the concept of the stored-program computer introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript on Deciphering Cryptographic Messages.
Use of a static code analysis tool can help detect some possible problems.
Techniques like Code refactoring can enhance readability.
This is interpreted into machine code.
Trial-and-error/divide-and-conquer is needed: the programmer will try to remove some parts of the original test case and check if the problem still exists.
Scripting and breakpointing is also part of this process.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
They are the building blocks for all software, from the simplest applications to the most sophisticated ones.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
 Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA).