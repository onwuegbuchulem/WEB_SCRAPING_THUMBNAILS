To produce machine code, the source code must either be compiled or transpiled.
Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.
Unreadable code often leads to bugs, inefficiencies, and duplicated code.
For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software.
It is usually easier to code in "high-level" languages than in "low-level" ones.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.
There are many approaches to the Software development process.
Text editors were also developed that allowed changes and corrections to be made much more easily than with punched cards.
When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
It is usually easier to code in "high-level" languages than in "low-level" ones.
 Allen Downey, in his book How To Think Like A Computer Scientist, writes:
 Many computer languages provide a mechanism to call functions provided by shared libraries.
The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
 Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display.
By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers.
 Computer programmers are those who write computer software.