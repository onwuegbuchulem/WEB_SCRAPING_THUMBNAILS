Compiling takes the source code from a low-level programming language and converts it into machine code.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices.
Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages.
Also, specific user environment and usage history can make it difficult to reproduce the problem.
Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.
In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where a musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams.
A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.
This is interpreted into machine code.
 Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation.
 Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.
The purpose of programming is to find a sequence of instructions that will automate the performance of a task (which can be as complex as an operating system) on a computer, often for solving a given problem.
For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input.
Assembly languages were soon developed that let the programmer specify instruction in a text format (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses.